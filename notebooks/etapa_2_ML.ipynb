#----------------------------------------------------------------------------
#----------------------------------------------------------------------------
import pandas as pd
from sklearn.model_selection import train_test_split, StratifiedKFold

#O arquivo [heart_disease_model_ready.csv] precisa estar na pasta raiz do Colab, ele é gerado na etapa 1
#Carregamento do dataset tratado
df = pd.read_csv('heart_disease_model_ready.csv')

#Separação das variáveis
# X: Matriz de features (todas as colunas menos 'num')
# y: Vetor alvo ('num'), onde 1 indica doença cardíaca e 0 indica saudável
X = df.drop('num', axis=1)
y = df['num']

# 3. Divisão dos dados (Hold-out Strategy)
# Utilizamos uma proporção de 80% para treino e 20% para teste.
# O parâmetro 'stratify=y' é crucial aqui: ele garante que a proporção de doentes/saudáveis
# seja mantida idêntica em ambos os conjuntos, evitando viés de seleção.
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.20,
    random_state=42, 
    stratify=y
)

# 4. Definição da Validação Cruzada (K-Fold)
# Para a etapa de treino, não usaremos uma divisão simples de validação.
# Em vez disso, aplicaremos Stratified K-Fold com k=5.
# Isso significa que o modelo será treinado e validado 5 vezes em "fatias" diferentes dos dados de treino.
cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Logs para verificação
print(f"Total de amostras: {len(df)}")
print(f"Dataset de Treino: {X_train.shape[0]} amostras ({X_train.shape[0]/len(df):.0%})")
print(f"Dataset de Teste:  {X_test.shape[0]} amostras ({X_test.shape[0]/len(df):.0%})")
#----------------------------------------------------------------------------
#----------------------------------------------------------------------------
# Conferência rápida do estado dos dados
print("--- Status do Pré-processamento ---")
print(f"Valores Nulos Restantes: {df.isnull().sum().sum()}")
print(f"Número de Colunas (após One-Hot Encoding): {df.shape[1]}")
print(f"Balanceamento das Classes (0 vs 1):\n{df['num'].value_counts(normalize=True)}")
#----------------------------------------------------------------------------
#----------------------------------------------------------------------------
import time
import platform
import psutil
import pandas as pd
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier

# --- 1. Definição do Espaço de Busca (Hiperparâmetros) ---

model_params = {
    "Regressão Logística": {
        "model": LogisticRegression(random_state=42, max_iter=2000),
        "params": {
            'C': [0.1, 1, 10, 100],          # Inverso da regularização (menor = mais forte)
            'solver': ['liblinear', 'lbfgs'] # Algoritmos de otimização
        }
    },
    "Random Forest": {
        "model": RandomForestClassifier(random_state=42),
        "params": {
            'n_estimators': [50, 100, 200],  # Número de árvores
            'max_depth': [None, 10, 20],     # Profundidade máxima da árvore
            'min_samples_leaf': [1, 2, 4]    # Mínimo de amostras na folha (evita overfitting)
        }
    },
    "SVM": {
        "model": SVC(random_state=42),
        "params": {
            'C': [0.1, 1, 10],               # Margem de erro (soft margin)
            'kernel': ['linear', 'rbf'],     # Tipo de kernel (linear ou radial)
            'gamma': ['scale', 'auto']       # Coeficiente do kernel
        }
    },
    "KNN": {
        "model": KNeighborsClassifier(),
        "params": {
            'n_neighbors': [3, 5, 7, 9, 11], # Número de vizinhos
            'weights': ['uniform', 'distance'], # Peso do voto (igual ou por distância)
            'metric': ['euclidean', 'manhattan'] # Como medir a distância
        }
    },
    "Gradient Boosting": {
        "model": GradientBoostingClassifier(random_state=42),
        "params": {
            'learning_rate': [0.01, 0.1, 0.2], # Velocidade de aprendizado
            'n_estimators': [50, 100, 200],    # Número de árvores sequenciais
            'max_depth': [3, 5]                # Profundidade de cada árvore
        }
    }
}

# --- 2. Execução da Otimização ---
results_tuning = []

print("Iniciando Otimização de Hiperparâmetros (Grid Search)...\n")

for model_name, mp in model_params.items():
    print(f"Otimizando {model_name}...")
    start_time = time.time() # Início do cronômetro
    
    # GridSearchCV:
    # - estimator: o modelo
    # - param_grid: as opções para testar
    # - cv=5: validação cruzada com 5 dobras
    # - scoring='accuracy': métrica para escolher o melhor
    # - n_jobs=-1: usa todos os processadores disponíveis para ir mais rápido
    clf = GridSearchCV(mp['model'], mp['params'], cv=5, scoring='accuracy', n_jobs=-1)
    clf.fit(X_train, y_train)
    
    end_time = time.time() # Fim do cronômetro
    duration = end_time - start_time
    
    # Guarda os resultados
    results_tuning.append({
        'Algoritmo': model_name,
        'Melhores Parâmetros': str(clf.best_params_),
        'Melhor Acurácia (Treino)': f"{clf.best_score_:.2%}",
        'Tempo (s)': f"{duration:.2f}"
    })

# --- 3. Coleta de Informações do Sistema ---
# Importante para o relatório: onde isso foi rodado?
sistema_info = {
    "Sistema Operacional": platform.system() + " " + platform.release(),
    "Processador": platform.processor(),
    "Núcleos Físicos": psutil.cpu_count(logical=True),
    "Memória RAM Total": f"{round(psutil.virtual_memory().total / (1024**3), 2)} GB"
}

# Exibição dos Resultados
print("\n" + "="*50)
print("RESULTADOS DA OTIMIZAÇÃO")
print("="*50)
df_results = pd.DataFrame(results_tuning)
display(df_results)

print("\n" + "="*50)
print("RECURSOS COMPUTACIONAIS")
print("="*50)
for k, v in sistema_info.items():
    print(f"{k}: {v}")
#----------------------------------------------------------------------------
#----------------------------------------------------------------------------
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    roc_auc_score, confusion_matrix, roc_curve
)

#IMPORTAÇÕES DOS MODELOS
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier



# 1) DEFINIR OS MODELOS E SEUS MELHORES PARÂMETROS


modelos = {
    "Logistic Regression": LogisticRegression(**{'C': 0.1, 'solver': 'liblinear'}, max_iter=1000),
    "Random Forest": RandomForestClassifier(**{'max_depth': 10, 'min_samples_leaf': 2, 'n_estimators': 200}),
    "SVM": SVC(**{'C': 1, 'gamma': 'auto', 'kernel': 'rbf'}, probability=True),
    "KNN": KNeighborsClassifier(**{'metric': 'euclidean', 'n_neighbors': 7, 'weights': 'uniform'}),
    "Gradient Boosting": GradientBoostingClassifier(**{'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 150})
}



# 2) FUNÇÃO PARA CALCULAR MÉTRICAS


def avaliar_modelo(modelo, X_train, y_train, X_test, y_test):

    modelo.fit(X_train, y_train)

    y_pred = modelo.predict(X_test)
    y_proba = modelo.predict_proba(X_test)[:, 1]

    metrics = {
        "Acurácia": accuracy_score(y_test, y_pred),
        "Precisão": precision_score(y_test, y_pred),
        "Recall": recall_score(y_test, y_pred),
        "F1": f1_score(y_test, y_pred),
        "AUC": roc_auc_score(y_test, y_proba)
    }

    return metrics, y_pred, y_proba



# 3) FUNÇÃO PARA PLOTAR MATRIZ DE CONFUSÃO + ROC


def plotar_graficos(y_test, y_pred, y_proba, titulo):
    fig, ax = plt.subplots(1, 2, figsize=(14, 6))

    # Matriz de Confusão
    cm = confusion_matrix(y_test, y_pred)
    sns.heatmap(
        cm, annot=True, fmt='d', cmap='Blues', ax=ax[0],
        xticklabels=['Saudável (0)', 'Doença (1)'],
        yticklabels=['Saudável (0)', 'Doença (1)']
    )
    ax[0].set_title(f'{titulo} - Matriz de Confusão')

    # Curva ROC
    fpr, tpr, _ = roc_curve(y_test, y_proba)
    ax[1].plot(fpr, tpr)
    ax[1].plot([0,1], [0,1], linestyle='--')
    ax[1].set_title(f'{titulo} - Curva ROC')
    ax[1].set_xlabel("FPR")
    ax[1].set_ylabel("TPR")

    plt.tight_layout()
    plt.show()



# 4) EXECUTAR TODOS OS MODELOS EM LOOP


resultados = {}

for nome, modelo in modelos.items():
    print("="*70)
    print(f"Treinando e avaliando: {nome}")
    print("="*70)

    metrics, y_pred, y_proba = avaliar_modelo(modelo, X_train, y_train, X_test, y_test)

    resultados[nome] = metrics

    for m, v in metrics.items():
        print(f"{m}: {v:.4f}")

    # gerar gráficos
    plotar_graficos(y_test, y_pred, y_proba, nome)
    print("\n\n")
#----------------------------------------------------------------------------
#----------------------------------------------------------------------------
#Feature importance
from sklearn.ensemble import GradientBoostingClassifier
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

#Treinamento do modelo
best_model = GradientBoostingClassifier(
    learning_rate=0.1,
    max_depth=3,
    n_estimators=150,
    random_state=42
)

best_model.fit(X_train, y_train)

melhor_modelo_nome = "Gradient Boosting"

if hasattr(best_model, "feature_importances_"):
    importances = best_model.feature_importances_

    feat_imp = pd.DataFrame({
        "Feature": X_train.columns,
        "Importância": importances
    }).sort_values("Importância", ascending=False)

    plt.figure(figsize=(8, 6))
    sns.barplot(data=feat_imp, x="Importância", y="Feature")
    plt.title(f"Importância das Features — {melhor_modelo_nome}")
    plt.tight_layout()
    plt.show()

    display(feat_imp)

