#-------------------------------------------------------------------------
#-------------------------------------------------------------------------
#Importação
import os
import random
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
  
from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder
from sklearn.impute import SimpleImputer
from google.colab import files
#-------------------------------------------------------------------------
#-------------------------------------------------------------------------
#Carregamento do dataset
# Primeiro, faço o upload da chave 'kaggle.json' que foi gerada no site do Kaggle.
# Essa chave é obrigatória para liberar o uso da API.
files.upload()
  
# Crio a pasta oculta onde o Kaggle espera encontrar a chave,
# copio o arquivo para lá e ajusto as permissões.
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
  
# Depois de configurada a chave, peço para baixar o dataset direto do Kaggle.
# O parâmetro -d indica o nome do repositório do dataset.
!kaggle datasets download -d redwankarimsony/heart-disease-data
  
# O arquivo chega compactado; aqui eu descompacto o conteúdo dentro da pasta "dataset".
!unzip -o heart-disease-data.zip -d dataset/
  
# Só para confirmar o que veio dentro do arquivo, listando a pasta.
!ls dataset/
  
# Carrego o arquivo CSV principal para um DataFrame do Pandas.
df = pd.read_csv("dataset/heart_disease_uci.csv")
#------------------------------------------------------------------------- 
#-------------------------------------------------------------------------
#Sumário do dataset
# Quantidade de Atributos e Instâncias
qtd_instancias, qtd_atributos = df.shape

# Tamanho do arquivo
file_path = 'dataset/heart_disease_uci.csv'
file_size = os.path.getsize(file_path)

# Exibição dos Resultados para o Relatório
print(f"********** Sumário do Dataset **********")
print(f"Quantidade de atributos/features: {qtd_atributos}")
print(f"Quantidade de instâncias/registros: {qtd_instancias}")
print(f"O tamanho do arquivo '{file_path}' é de {file_size} bytes.")
#------------------------------------------------------------------------- 
#-------------------------------------------------------------------------
#Descrição das features
feature_info = []

descriptions = {
    'id': 'Identificador único para cada registro de paciente.',
    'age': 'Idade do paciente em anos.',
    'sex': 'Sexo do paciente (masculino/feminino).',
    'dataset': 'Conjunto de dados de origem do qual o registro se originou.',
    'cp': 'Tipo de dor no peito (por exemplo, angina típica, assintomática).',
    'trestbps': 'Pressão arterial em repouso (em mm Hg na admissão ao hospital)..',
    'chol': 'Colesterol sérico em mg/dl..',
    'fbs': 'Glicemia em jejum > 120 mg/dl (Verdadeiro/Falso).',
    'restecg': 'Resultados do eletrocardiograma em repouso (por exemplo, normal, hipertrofia ventricular esquerda).',
    'thalch': 'Frequência cardíaca máxima alcançada.',
    'exang': 'Angina induzida por exercício (Verdadeiro/Falso).',
    'oldpeak': 'Depressão do segmento ST induzida pelo exercício em relação ao repouso.',
    'slope': 'A inclinação do segmento ST no pico do exercício (por exemplo, ascendente, plana, descendente).',
    'ca': 'Número de vasos principais (0-3) coloridos por fluoroscopia.',
    'thal': 'Talassemia (por exemplo, normal, defeito fixo, defeito reversível).',
    'num': 'Diagnóstico de doença cardíaca (estado da doença angiográfica) (0 = sem doença, >0 = presença de doença).'
}

for col in df.columns:
    feature_info.append({
        'Feature': col,
        'Tipo do dado': str(df[col].dtype),
        'Descrição': descriptions.get(col, 'No description available.'),
        'Exemplo': str(df[col].iloc[0]) if not df[col].isnull().all() else 'NaN'
    })

features_summary_df = pd.DataFrame(feature_info)
display(features_summary_df)
#------------------------------------------------------------------------- 
#-------------------------------------------------------------------------
#Conteúdo do dataset
display(df.head())
display(df.tail())
#------------------------------------------------------------------------- 
#-------------------------------------------------------------------------
#Medidas estatísticas
# Pega todas as colunas numéricas
numerical_cols = df.select_dtypes(include=['number']).columns.drop('id', errors='ignore')

summary = df[numerical_cols].describe().T

# Seleciona e reordena as colunas para ficar no formato desejado
summary = summary[['min', '25%', '50%', '75%', 'max', 'mean', 'std']]

print(summary)
#------------------------------------------------------------------------- 
#-------------------------------------------------------------------------
#Análise visual dos dados
#Histograma de feature numérica
# Colunas numéricas
num_cols = ['trestbps', 'chol', 'thalch', 'oldpeak', 'ca']

plt.figure(figsize=(18, 12))

# Loop e plot
for i, col in enumerate(num_cols):
    plt.subplot(3, 2, i + 1)
    # .dropna() para evitar erros se houver nulos
    sns.histplot(df[col].dropna(), kde=True)
    plt.title(f'Histograma de {col}')

plt.tight_layout()
plt.show()
#Gráfico features categóricas
# Contagem das colunas categóricas
cols_to_plot = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'thal', 'num']

plt.figure(figsize=(20, 15))

for i, col in enumerate(cols_to_plot):
    plt.subplot(3, 3, i + 1)

    # Faz um countplot para a coluna
    sns.countplot(x=col, data=df, hue=col, palette='viridis', legend=False)


    plt.title(f'Contagem de {col}')
    plt.xlabel(None)
    plt.ylabel('Contagem')

    plt.xticks(rotation=45, ha='right')

plt.tight_layout()
plt.show()
#------------------------------------------------------------------------- 
#-------------------------------------------------------------------------
#Verificação da qualidade dos dados
#Valores ausentes
# Contar os nulos
nulos = df.isnull().sum()

# Filtrar só as colunas que têm nulos
nulos_reais = nulos[nulos > 0]

if nulos_reais.empty:
    print("O dataset está limpo. Sem valores ausentes!")
else:
    print("Colunas com valores faltando (do maior para o menor):")
    print(nulos_reais.sort_values(ascending=False))


# Ver quantos % dos dados estão faltando
percent_faltando = (df.isnull().sum() / len(df)) * 100

# Filtra só as colunas que têm dados faltando
percent_faltando = percent_faltando[percent_faltando > 0]

if percent_faltando.empty:
    print("Dataset está 100% preenchido. Sem nulos.")
else:
    print("Percentual de dados ausentes por coluna:")

    # Ordena e aplica a formatação com 2 casas decimais e o %
    print(percent_faltando.sort_values(ascending=False).map("{:.2f}%".format))

#Estratégia para tratamento
import numpy as np
import pandas as pd

# --- Substitui '?' por NaN ---
df = df.replace('?', np.nan)

# --- Converte colunas numéricas corretamente ---
cols_to_num = ['ca', 'trestbps', 'chol', 'thalch', 'oldpeak']
df[cols_to_num] = df[cols_to_num].apply(pd.to_numeric, errors='coerce')

# --- LIMPEZA DE NULOS ---

# 1. Remove linhas onde 'restecg' é nulo
print(f"Linhas antes de dropar 'restecg': {len(df)}")
df = df.dropna(subset=['restecg'])
print(f"Linhas depois: {len(df)}")

# 2. Preenche colunas contínuas com a MEDIANA
median_cols = ['oldpeak', 'trestbps', 'thalch', 'chol']
for col in median_cols:
    med = df[col].median()
    df[col] = df[col].fillna(med)
    print(f"Nulos de '{col}' preenchidos com mediana: {med}")

# 3. Preenche colunas categóricas com a MODA
mode_cols = ['ca', 'thal', 'slope', 'fbs', 'exang']
for col in mode_cols:
    moda = df[col].mode(dropna=True)
    if not moda.empty:
        val = moda.iloc[0]
        df[col] = df[col].fillna(val)
        print(f"Nulos de '{col}' preenchidos com moda: {val}")
    else:
        print(f"A coluna '{col}' não possui valor de moda válido!")

#Outlier
# Colunas numéricas para checagem
cols_numericas = ['age', 'trestbps', 'chol', 'thalch', 'oldpeak']

# Resumo dos números
print("Resumo estatístico:")
print(df[cols_numericas].describe().T) # O .T (transposto) facilita a leitura

# Boxplots para outliers
plt.figure(figsize=(15, 10))

for i, col in enumerate(cols_numericas):
    # Adiciona o plot na posição i+1
    plt.subplot(2, 3, i + 1)
    sns.boxplot(y=df[col])
    plt.title(f'Boxplot de {col}')
    plt.ylabel(None)

plt.tight_layout()
plt.show()

#Dados inválidos ou erros
# Corrigir 'trestbps' (pressão 0 é impossível)
# Pega a mediana dos valores válidos (acima de 0)
mediana_trestbps = df[df['trestbps'] > 0]['trestbps'].median()
# Substitui todos os 0 pela mediana
df['trestbps'] = df['trestbps'].replace(0, mediana_trestbps)
print(f"Valores '0' em 'trestbps' corrigidos com {mediana_trestbps}")

# Corrigir 'chol' (colesterol 0 é impossível)
mediana_chol = df[df['chol'] > 0]['chol'].median()
# Substitui todos os 0 pela mediana
df['chol'] = df['chol'].replace(0, mediana_chol)
print(f"Valores '0' em 'chol' corrigidos com {mediana_chol}")

# Corrigir 'oldpeak' (valores negativos são erros)
mediana_oldpeak = df[df['oldpeak'] >= 0]['oldpeak'].median()
# Substitui todos os negativos (< 0) pela mediana
df.loc[df['oldpeak'] < 0, 'oldpeak'] = mediana_oldpeak
print(f"Valores negativos em 'oldpeak' corrigidos com {mediana_oldpeak}")

# Checagem rápida
print("\n--- Verificação (Valores Mínimos) ---")
print(f"Novo Mínimo 'trestbps': {df['trestbps'].min()}")
print(f"Novo Mínimo 'chol': {df['chol'].min()}")
print(f"Novo Mínimo 'oldpeak': {df['oldpeak'].min()}")

#Transformações
# Faz uma cópia para o processamento
df_processado = df.copy()

# --- 1. Features Categóricas ---

# Converte binárias (0/1)
df_processado['sex'] = df_processado['sex'].map({'Female': 0, 'Male': 1})
df_processado['fbs'] = df_processado['fbs'].astype(int)
df_processado['exang'] = df_processado['exang'].astype(int)

# Converte nominais (One-Hot Encoding)
cols_one_hot = ['cp', 'restecg', 'slope', 'thal']
df_processado = pd.get_dummies(df_processado, columns=cols_one_hot, dtype=int)

# --- 2. Features Numéricas (Padronização) ---

# Define as colunas para escalar
cols_to_scale = ['age', 'trestbps', 'chol', 'thalch', 'oldpeak']
scaler = StandardScaler()

# Aplica o scaler (z-score)
df_processado[cols_to_scale] = scaler.fit_transform(df_processado[cols_to_scale])

# --- 3. Target (Alvo) ---

# Torna binário: 0 (saudável) vs 1 (doente)
df_processado['num'] = (df_processado['num'] > 0).astype(int)

# --- 4. Limpeza Final ---

# Remove colunas que não servirão ao modelo
cols_to_drop = [col for col in ['id', 'dataset'] if col in df_processado.columns]
df_processado = df_processado.drop(columns=cols_to_drop)

# --- 5. Salvar ---
df_processado.to_csv('heart_disease_model_ready.csv', index=False)

print("Processamento concluído. Arquivo salvo.")
print(df_processado.info())

#------------------------------------------------------------------------- 
#-------------------------------------------------------------------------
#Download do CSV tratado
# Download do csv final
arquivo_final = 'heart_disease_model_ready.csv'

files.download(arquivo_final)
